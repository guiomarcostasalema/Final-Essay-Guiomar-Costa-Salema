{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Analysis of Greek News Industry Coverage on Turkish Relations: A Data-driven Approach**"
      ],
      "metadata": {
        "id": "Mw8mEO9FQJxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Exploring sentiment, temporal trends, and textual similarities using web scraping and NLP techniques*"
      ],
      "metadata": {
        "id": "OdcbI5sQQfQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTRODUCTION**"
      ],
      "metadata": {
        "id": "yMAsl0CVNG4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dynamics of Greek-Turkish ties have garnered a lot of attention recently in the Greek news community. The goal of this project is to present a data-driven examination of the media coverage of this subject. I will examine the feelings conveyed, temporal patterns, and linguistic similarities among news items using web scraping methods and natural language processing (NLP) technologies. My investigation will clarify the dominant myths and trends in the Greek news sector about Greek-Turkish relations."
      ],
      "metadata": {
        "id": "vy-Ohu7CNKIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Data Extraction and Preparation**"
      ],
      "metadata": {
        "id": "DEhgOLE7NrXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used web scraping methods with Python's requests and beautifulsoup modules to compile a sizable corpus of data. Over 500 news stories about Greek-Turkish ties were gathered by concentrating on well-known Greek news websites. The retrieved information was organized and stored as.csv files.\n",
        "\n",
        "The data was then imported into Python and dataframes were created using the pandas package for quick processing and analysis. By deleting useless information, erasing NaN values, and discarding extraneous text and columns, I made sure the data was cleansed. To improve the quality of the textual data, further preprocessing procedures such stopword removal, stemming, or lemmatization were carried out."
      ],
      "metadata": {
        "id": "z0h-YHHsN1YU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Temporal Analysis and Visualizations**"
      ],
      "metadata": {
        "id": "wq_D4DRhOPuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used the date column to set it as the dataframe's index, which gave us access to time series analysis tools. To organize and analyze the data depending on various time periods, such as day, month, three months, or year, we utilized the resample() method.\n",
        "\n",
        "In order to identify temporal patterns and trends in the coverage of Greek-Turkish relations, visualizations were used. To depict the amount and intensity of news coverage over time, time series line plots, bar charts, or heatmaps were used. These graphic representations will make it easier to spot significant developments or changes in the narrative in the Greek news sector.\n"
      ],
      "metadata": {
        "id": "Ag8AqQ00OTOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Sentiment Analysis**"
      ],
      "metadata": {
        "id": "NF2wD7lnOgNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used sentiment analysis methods to probe further into the sentiment presented in the news stories. Greek dictionaries or well-known lexicons like EmoLex were used to rate the articles' emotion. The dataframe's new column now contains the sentiment scores.\n",
        "\n",
        "I may investigate the predominant attitudes on Greek-Turkish relations in the Greek news sector using sentiment analysis. I may investigate how sentiments change over time and spot sentiment shifts in response to important events or changes in policy by categorizing the sentiment data using the resample method."
      ],
      "metadata": {
        "id": "I1onsSA_OkDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Textual Similarity Analysis**"
      ],
      "metadata": {
        "id": "5h6L76vrO13K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used vectorization methods and cosine similarity calculations to identify textual overlaps between the news items. I expressed the articles as numerical vectors in a high-dimensional space by vectorizing them. The similarity between these vectors was then determined using cosine similarity.\n",
        "\n",
        "I made a graph that illustrates the associations between the news stories based on their linguistic similarity using the similarity scores. The Greek news industry's common themes or narratives surrounding Greek-Turkish relations will be shown by clusters or groupings of stories with a high degree of textual similarity."
      ],
      "metadata": {
        "id": "DonmDezjO-vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSION**"
      ],
      "metadata": {
        "id": "Eije72jVPWps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have learned a lot about how the Greek news business covers Greek-Turkish relations by using web scraping, NLP methods, and data analysis. My investigation included textual comparisons, sentiment analysis, and temporal patterns, giving us a complete picture of the dominant narratives, emotions, and connections in the market.\n",
        "This data-driven approach helps us to appreciate the dynamics of Greek-Turkish relations from the viewpoint of the Greek news industry. Academics, policymakers, and anybody else with an interest in the evolving environment of Greek-Turkish relations and how it is depicted in Greek media may find the findings of this investigation to be a helpful resource.\n",
        "These methods can help the Greek news sector obtain a greater understanding of its coverage patterns, sentiment dynamics, and textual parallels, allowing for more insightful and nuanced reporting on Greek-Turkish relations and other significant issues of interest."
      ],
      "metadata": {
        "id": "m2w2AOzVPiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CODING**"
      ],
      "metadata": {
        "id": "1PiYlLY4zWYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Data Extraction and Preparation**"
      ],
      "metadata": {
        "id": "7Ov6Slp4p5uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mjw19K9Vp9-V"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web Scraping"
      ],
      "metadata": {
        "id": "iXeDo2VIqI7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://example.com/greek-turkish-relations\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "articles = soup.find_all('article')"
      ],
      "metadata": {
        "id": "iXYvxehxqFtO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving Data as CSV"
      ],
      "metadata": {
        "id": "IiNeIxBlqRhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "df.to_csv('greek_turkish_relations.csv', index=False)"
      ],
      "metadata": {
        "id": "MFeWoOdYqXyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Import the Data into Python**"
      ],
      "metadata": {
        "id": "AnvPR3tmqao2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OC1GlpLQqdIM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the CSV file into a DataFrame"
      ],
      "metadata": {
        "id": "jdEFJicrqjlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('greek_turkish_relations.csv')"
      ],
      "metadata": {
        "id": "x1ItpFP9qoub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Data Cleaning**"
      ],
      "metadata": {
        "id": "EIWQpXKRqts2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pnE_ysKIq2kI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing unnecessary columns"
      ],
      "metadata": {
        "id": "E8K8Zy-5rAOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['column1', 'column2'], axis=1)"
      ],
      "metadata": {
        "id": "MDDyAZXorJWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing rows with NaN values"
      ],
      "metadata": {
        "id": "2wFXbLctrEkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "PyxCQXr9rN3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning text data (remove stopwords, stemming, lemmatization, etc.)"
      ],
      "metadata": {
        "id": "WcEjn21OrUyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('greek'))\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
      ],
      "metadata": {
        "id": "dOXtky_rrWf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Create New Parameters**"
      ],
      "metadata": {
        "id": "d2DY5aERrcEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ZbmjE01irkbn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting month, time, and percentage"
      ],
      "metadata": {
        "id": "HJCKYJavrqCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['month'] = pd.to_datetime(df['date']).dt.month\n",
        "df['time'] = pd.to_datetime(df['date']).dt.time\n",
        "df['percentage'] = df['count'] / df['total'] * 100"
      ],
      "metadata": {
        "id": "fabHfypRruy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Perform Analyses and Create Graphs**"
      ],
      "metadata": {
        "id": "nFkEeJRCrxc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wgAX2lL6r0FX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wordcloud"
      ],
      "metadata": {
        "id": "asDc2BRRr5X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "wordcloud = WordCloud().generate(' '.join(df['text']))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LvTyXr6fr6c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency chart of most frequent words"
      ],
      "metadata": {
        "id": "eNZnf9e0r82M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_words = df['text'].str.split(expand=True).stack().value_counts().head(15)\n",
        "top_words.plot(kind='bar')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 15 Most Frequent Words')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oty0B7BysB0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency chart of most frequent bigrams"
      ],
      "metadata": {
        "id": "DiE61D50sIZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "bigrams = list(ngrams(df['text'].str.split().explode().tolist(), 2))\n",
        "top_bigrams = pd.Series(bigrams).value_counts().head(15)\n",
        "top_bigrams.plot(kind='bar')\n",
        "plt.xlabel('Bigrams')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 15 Most Frequent Bigrams')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3hzeCICYsJPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Time Series Analysis**"
      ],
      "metadata": {
        "id": "d-NYOUjxsdPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BJMoDuucsfXJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting date as index"
      ],
      "metadata": {
        "id": "KLQZldXrslFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)"
      ],
      "metadata": {
        "id": "5EXmHkvRsmCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resampling data by month and calculate the mean sentiment"
      ],
      "metadata": {
        "id": "yjO1jnGNsoXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_sentiment = df['sentiment'].resample('M').mean()"
      ],
      "metadata": {
        "id": "QLxJUTPQsrAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting time series line plot"
      ],
      "metadata": {
        "id": "gEJURtDxst3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_sentiment.plot()\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sentiment')\n",
        "plt.title('Monthly Sentiment on Greek-Turkish Relations')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h_4Zqfcns0eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Sentiment Analysis**"
      ],
      "metadata": {
        "id": "zS-FyyKEs3L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zh4ii8E5s65x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df['text'].apply(sentiment_analysis_function)"
      ],
      "metadata": {
        "id": "_iIYVbLwtFWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Grouping and Resampling**"
      ],
      "metadata": {
        "id": "9da6oQu9tJf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mImOFj62tVia"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouping sentiment by month and calculate the mean sentiment"
      ],
      "metadata": {
        "id": "UA_toUIhtjqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_sentiment = df['sentiment'].resample('M').mean()"
      ],
      "metadata": {
        "id": "G9_AHEpbtoW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouping sentiment by day and calculate the mean sentiment"
      ],
      "metadata": {
        "id": "s_aQj1IjtrAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_sentiment = df['sentiment'].resample('D').mean()"
      ],
      "metadata": {
        "id": "nI_9taeztsfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9: Textual Similarity Analysis**"
      ],
      "metadata": {
        "id": "xYb1-aO8tvdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "zc6Kv8b-t0CI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing the articles"
      ],
      "metadata": {
        "id": "zRI0kMeHt5hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(df['text'])"
      ],
      "metadata": {
        "id": "ixAmKbCFt6dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating cosine similarity between the vectors"
      ],
      "metadata": {
        "id": "cDBlyoVRt-yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix = cosine_similarity(vectors)\n"
      ],
      "metadata": {
        "id": "9QhuRGS_t_3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8Eyc5mwAuCkU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()\n",
        "G.add_nodes_from(df.index)\n",
        "for i in range(len(df.index)):\n",
        "for j in range(i + 1, len(df.index)):\n",
        "similarity = similarity_matrix[i, j]\n",
        "if similarity > 0.5:\n",
        "G.add_edge(df.index[i], df.index[j], weight=similarity)"
      ],
      "metadata": {
        "id": "yWpNU7iruHSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos = nx.spring_layout(G)\n",
        "labels = {node: str(node.date()) for node in G.nodes()}\n",
        "nx.draw_networkx(G, pos, labels=labels)\n",
        "plt.title('Textual Similarity Graph')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mHHzkd7YuNNO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}